data <- iris
data
data_creat<-function(){
data <- iris
save(iris,file="Data/data.Rdata")
return(data)
}
data_creat()
data_creat<-function(){
data <- iris
save(data,file="Data/data.Rdata")
load(file="Data/data.Rdata")
}
data_creat()
data
# Created by use_targets().
# Follow the comments below to fill in this target script.
# Then follow the manual to check and run the pipeline:
#   https://books.ropensci.org/targets/walkthrough.html#inspect-the-pipeline
rm(list=ls())
# Load packages required to define the pipeline:
library(targets)
# Set target options:
tar_option_set(
packages = c("readr", "dplyr", "ggplot2", "tibble", "car") # Packages that your targets need for their tasks.
# format = "qs", # Optionally set the default storage format. qs is fast.
#
# Pipelines that take a long time to run may benefit from
# optional distributed computing. To use this capability
# in tar_make(), supply a {crew} controller
# as discussed at https://books.ropensci.org/targets/crew.html.
# Choose a controller that suits your needs. For example, the following
# sets a controller that scales up to a maximum of two workers
# which run as local R processes. Each worker launches when there is work
# to do and exits if 60 seconds pass with no tasks to run.
#
#   controller = crew::crew_controller_local(workers = 2, seconds_idle = 60)
#
# Alternatively, if you want workers to run on a high-performance computing
# cluster, select a controller from the {crew.cluster} package.
# For the cloud, see plugin packages like {crew.aws.batch}.
# The following example is a controller for Sun Grid Engine (SGE).
#
#   controller = crew.cluster::crew_controller_sge(
#     # Number of workers that the pipeline can scale up to:
#     workers = 10,
#     # It is recommended to set an idle time so workers can shut themselves
#     # down if they are not running tasks.
#     seconds_idle = 120,
#     # Many clusters install R as an environment module, and you can load it
#     # with the script_lines argument. To select a specific verison of R,
#     # you may need to include a version string, e.g. "module load R/4.3.2".
#     # Check with your system administrator if you are unsure.
#     script_lines = "module load R"
#   )
#
# Set other options as needed.
)
# Run the R scripts in the R/ folder with your custom functions:
tar_source("R/FUNCTIONS_iris.R")
# Replace the target list below with your own:
list(
tar_target(data, data_creat(iris)),
tar_target(resume, Res_data(data)),
tar_target(plot, Plot_length(resume)),
tar_target(AnovaIris, AnovaTest_iris(data, data$Sepal.Length, data$Species)))
Sys.setenv(TAR_PROJECT = "Reproducibility_iris")
tar_manifest(fields = command)
tar_visnetwork()
tar_make()
data_creat<-function(){
data <- iris
save(data,file="Data/data.Rdata")
as.data.frame(load(file="Data/data.Rdata"))
}
data_creat()
data_creat<-function(){
data <- iris
save(data,file="Data/data.Rdata")
data <- load(file="Data/data.Rdata")
data.frame(data)
}
data_creat()
data
data_creat<-function(){
data <- iris
save(data,file="Data/data.Rdata")
load(file="Data/data.Rdata")
as.data.frame(data)
}
data_creat()
class(data)
data_creat<-function(){
data <- iris
save(data,file="Data/data.Rdata")
load(file="Data/data.Rdata")
as.data.frame(data)
}
data_creat()
data_creat<-function(){
data <- iris
save(data,file="Data/data.Rdata")
load(file="Data/data.Rdata") %>%
data.frame()
}
data_creat()
data_creat<-function(){
data <- iris %>%
data.frame()
}
rm(list=ls())
data_creat<-function(){
data <- iris %>%
data.frame()
}
data_creat()
data
class(data)
data_creat<-function(){
data <- iris
save(data,file="Data/data.Rdata")
load(file="Data/data.Rdata")
}
data_creat()
data
rm(list=ls())
data_creat<-function(){
data <- iris
save(data,file="Data/data.Rdata")
load(file="Data/data.Rdata")
}
data_creat()
data
class(data)
data_creat<-function(){
Data <- iris
save(data,file="Data/data_iris.Rdata")
load(file="Data/data_iris.Rdata")
}
data_creat()
data_iris
Data <- iris
save(data,file="Data/data_iris.Rdata")
load(file="Data/data_iris.Rdata")
data_iris
data_creat<-function(){
Data <- iris
save(Data,file="Data/data_iris.Rdata")
load(file="Data/data_iris.Rdata")
}
data_creat()
data_iris
Data <- iris
save(Data,file="Data/data_iris.Rdata")
load(file="Data/data_iris.Rdata")
data_iris
load("~/Rstats/Projects/Reproducibility/Data/data_iris.Rdata")
data_iris.Rdata
rm(list=ls())
Data <- iris
rm(list=ls())
load(file="Data/data_iris.Rdata")
data_creat<-function(){
Data <- iris
save(Data,file="Data/data_iris.Rdata")
load(file="Data/data_iris.Rdata")
}
data_creat()
Data
class(Data)
# Created by use_targets().
# Follow the comments below to fill in this target script.
# Then follow the manual to check and run the pipeline:
#   https://books.ropensci.org/targets/walkthrough.html#inspect-the-pipeline
rm(list=ls())
# Load packages required to define the pipeline:
library(targets)
# Set target options:
tar_option_set(
packages = c("readr", "dplyr", "ggplot2", "tibble", "car") # Packages that your targets need for their tasks.
# format = "qs", # Optionally set the default storage format. qs is fast.
#
# Pipelines that take a long time to run may benefit from
# optional distributed computing. To use this capability
# in tar_make(), supply a {crew} controller
# as discussed at https://books.ropensci.org/targets/crew.html.
# Choose a controller that suits your needs. For example, the following
# sets a controller that scales up to a maximum of two workers
# which run as local R processes. Each worker launches when there is work
# to do and exits if 60 seconds pass with no tasks to run.
#
#   controller = crew::crew_controller_local(workers = 2, seconds_idle = 60)
#
# Alternatively, if you want workers to run on a high-performance computing
# cluster, select a controller from the {crew.cluster} package.
# For the cloud, see plugin packages like {crew.aws.batch}.
# The following example is a controller for Sun Grid Engine (SGE).
#
#   controller = crew.cluster::crew_controller_sge(
#     # Number of workers that the pipeline can scale up to:
#     workers = 10,
#     # It is recommended to set an idle time so workers can shut themselves
#     # down if they are not running tasks.
#     seconds_idle = 120,
#     # Many clusters install R as an environment module, and you can load it
#     # with the script_lines argument. To select a specific verison of R,
#     # you may need to include a version string, e.g. "module load R/4.3.2".
#     # Check with your system administrator if you are unsure.
#     script_lines = "module load R"
#   )
#
# Set other options as needed.
)
# Run the R scripts in the R/ folder with your custom functions:
tar_source("R/FUNCTIONS_iris.R")
# Replace the target list below with your own:
list(
tar_target(Data, data_creat(iris)),
tar_target(resume, Res_data(Data)),
tar_target(plot, Plot_length(resume)),
tar_target(AnovaIris, AnovaTest_iris(Data, Data$Sepal.Length, Data$Species)))
Sys.setenv(TAR_PROJECT = "Reproducibility_iris")
tar_manifest(fields = command)
tar_make()
# Replace the target list below with your own:
list(
tar_target(Data, data_creat()),
tar_target(resume, Res_data(Data)),
tar_target(plot, Plot_length(resume)),
tar_target(AnovaIris, AnovaTest_iris(Data, Data$Sepal.Length, Data$Species)))
tar_make()
# Created by use_targets().
# Follow the comments below to fill in this target script.
# Then follow the manual to check and run the pipeline:
#   https://books.ropensci.org/targets/walkthrough.html#inspect-the-pipeline
rm(list=ls())
# Load packages required to define the pipeline:
library(targets)
# Set target options:
tar_option_set(
packages = c("readr", "dplyr", "ggplot2", "tibble", "car") # Packages that your targets need for their tasks.
# format = "qs", # Optionally set the default storage format. qs is fast.
#
# Pipelines that take a long time to run may benefit from
# optional distributed computing. To use this capability
# in tar_make(), supply a {crew} controller
# as discussed at https://books.ropensci.org/targets/crew.html.
# Choose a controller that suits your needs. For example, the following
# sets a controller that scales up to a maximum of two workers
# which run as local R processes. Each worker launches when there is work
# to do and exits if 60 seconds pass with no tasks to run.
#
#   controller = crew::crew_controller_local(workers = 2, seconds_idle = 60)
#
# Alternatively, if you want workers to run on a high-performance computing
# cluster, select a controller from the {crew.cluster} package.
# For the cloud, see plugin packages like {crew.aws.batch}.
# The following example is a controller for Sun Grid Engine (SGE).
#
#   controller = crew.cluster::crew_controller_sge(
#     # Number of workers that the pipeline can scale up to:
#     workers = 10,
#     # It is recommended to set an idle time so workers can shut themselves
#     # down if they are not running tasks.
#     seconds_idle = 120,
#     # Many clusters install R as an environment module, and you can load it
#     # with the script_lines argument. To select a specific verison of R,
#     # you may need to include a version string, e.g. "module load R/4.3.2".
#     # Check with your system administrator if you are unsure.
#     script_lines = "module load R"
#   )
#
# Set other options as needed.
)
# Run the R scripts in the R/ folder with your custom functions:
tar_source("R/FUNCTIONS_iris.R")
# Replace the target list below with your own:
list(
tar_target(Data, data_creat()),
tar_target(resume, Res_data(Data)),
tar_target(plot, Plot_length(resume)),
tar_target(AnovaIris, AnovaTest_iris(Data, Data$Sepal.Length, Data$Species)))
Sys.setenv(TAR_PROJECT = "Reproducibility_iris")
tar_make()
tar_make()
tar_errored()
Data <- iris
library(readr)
library(tidyr)
# Load packages required to define the pipeline:
library(targets)
# Set target options:
tar_option_set(
packages = c("readr", "dplyr", "ggplot2", "tibble", "car") # Packages that your targets need for their tasks.
# format = "qs", # Optionally set the default storage format. qs is fast.
#
# Pipelines that take a long time to run may benefit from
# optional distributed computing. To use this capability
# in tar_make(), supply a {crew} controller
# as discussed at https://books.ropensci.org/targets/crew.html.
# Choose a controller that suits your needs. For example, the following
# sets a controller that scales up to a maximum of two workers
# which run as local R processes. Each worker launches when there is work
# to do and exits if 60 seconds pass with no tasks to run.
#
#   controller = crew::crew_controller_local(workers = 2, seconds_idle = 60)
#
# Alternatively, if you want workers to run on a high-performance computing
# cluster, select a controller from the {crew.cluster} package.
# For the cloud, see plugin packages like {crew.aws.batch}.
# The following example is a controller for Sun Grid Engine (SGE).
#
#   controller = crew.cluster::crew_controller_sge(
#     # Number of workers that the pipeline can scale up to:
#     workers = 10,
#     # It is recommended to set an idle time so workers can shut themselves
#     # down if they are not running tasks.
#     seconds_idle = 120,
#     # Many clusters install R as an environment module, and you can load it
#     # with the script_lines argument. To select a specific verison of R,
#     # you may need to include a version string, e.g. "module load R/4.3.2".
#     # Check with your system administrator if you are unsure.
#     script_lines = "module load R"
#   )
#
# Set other options as needed.
)
# Run the R scripts in the R/ folder with your custom functions:
tar_source("R/01_Load_gasar.R")
tar_source("R/02_Res_gasar.R")
tar_source("R/03_Plot_length_gasar.R")
tar_source("R/04_AnovaTest_gasar.R")
# Replace the target list below with your own:
list(
tar_target(file, "Data/Allo.csv", format="file"),
tar_target(data, load_gasar(file)), # rds is the default format. see https://docs.ropensci.org/targets/reference/tar_target.html#storage-formats for other formats
tar_target(Resume, Res_gasar(data)),
tar_target(Plot, Plot_length(Resume)),
tar_target(Anova_gasar_Length_Station, AnovaTest_gasar(data, data$Longueurs, data$Station)))
Sys.setenv(TAR_PROJECT = "Own")
tar_visnetwork()
librarie(renv)
library(renv)
install.packages("renv")
library(renv)
renv::init()
install.packages("yalm")
install.packages("yaml")
usethis::use_git()
install.packages("usethis")
usethis::use_git()
renv::status()
renv::snapshot()
renv::status()
knitr::knit_engines$get()
usethis::git_remotes()
library(usethis)
usethis::gitcreds_set()
gitcreds::gitcreds_set()
renv::restore()
library(readr)
Allo <- read_delim("Data/Allo.csv", delim = "\t",
escape_double = FALSE, trim_ws = TRUE)
View(Allo)
library(tidyverse)
library(tidyr)
library(dplyr)
renv::resore()
renv::restore()
library(tidyr)
renv::status()
renv::restore()
install.packages("tidyr")
install.packages("dplyr")
library(tidyr)
library(dplyr)
?filter()
tidy <- Allo %>%
ifelse(Station=="Missirah", filter(Espece!="Anadara_senilis",))
tidy <- Allo %>%
filter(ifelse(Station=="Missirah", filter(Espece!="Anadara_senilis",)))
filtre <- function(data,var1,val1, var2,val2){
if(data$var1==val1){
data %>%
filter(var2!=val2)
}
}
tidy <- filtre(Allo,Station,"Missirah",Espece,"Anadara_senilis")
filtre <- function(data,var1,val1, var2,val2){
if(data$var1==val1){
data %>%
filter(var2!=val2)
}
}
filtre <- function(data,var1,val1, var2,val2){
if(data$var1==val1){
data %>%
filter(var2!=val2)
}
}
tidy <- filtre(Allo,Station,Missirah,Espece,"Anadara_senilis")
tidy <- Allo %>%
unite(NEW,Station,Espece, sep = "_") %>%
filter(NEW!="Missirah_Anadara_senilis")
View(tidy)
?separate()
renv::install("styler")
quit()
?style_pkg()
styler::style_pkg()
?styler::style_pkg()
?styler::style_file()
?styler::style_text()
styler:::style_selection()
styler:::style_selection()
styler:::style_selection()
styler:::set_style_transformers()
styler:::set_style_transformers()
styler()
?styler
styler:::style_selection()
styler:::style_selection()
renv::restore()
renv::status()
?renv::status
renv::snapshot()
tinytex::install_tinytex()
quit()
# Created by use_targets().
# Follow the comments below to fill in this target script.
# Then follow the manual to check and run the pipeline:
#   https://books.ropensci.org/targets/walkthrough.html#inspect-the-pipeline
rm(list = ls())
# Load packages required to define the pipeline:
library(targets)
# library(tarchetypes) # Load other packages as needed.
# Set target options:
tar_option_set(
packages = c("readr", "dplyr", "ggplot2", "tibble", "car") # Packages that your targets need for their tasks.
# format = "qs", # Optionally set the default storage format. qs is fast.
#
# Pipelines that take a long time to run may benefit from
# optional distributed computing. To use this capability
# in tar_make(), supply a {crew} controller
# as discussed at https://books.ropensci.org/targets/crew.html.
# Choose a controller that suits your needs. For example, the following
# sets a controller that scales up to a maximum of two workers
# which run as local R processes. Each worker launches when there is work
# to do and exits if 60 seconds pass with no tasks to run.
#
#   controller = crew::crew_controller_local(workers = 2, seconds_idle = 60)
#
# Alternatively, if you want workers to run on a high-performance computing
# cluster, select a controller from the {crew.cluster} package.
# For the cloud, see plugin packages like {crew.aws.batch}.
# The following example is a controller for Sun Grid Engine (SGE).
#
#   controller = crew.cluster::crew_controller_sge(
#     # Number of workers that the pipeline can scale up to:
#     workers = 10,
#     # It is recommended to set an idle time so workers can shut themselves
#     # down if they are not running tasks.
#     seconds_idle = 120,
#     # Many clusters install R as an environment module, and you can load it
#     # with the script_lines argument. To select a specific verison of R,
#     # you may need to include a version string, e.g. "module load R/4.3.2".
#     # Check with your system administrator if you are unsure.
#     script_lines = "module load R"
#   )
#
# Set other options as needed.
)
# Run the R scripts in the R/ folder with your custom functions:
tar_source("R/01_Load_gasar.R")
tar_source("R/02_Res_gasar.R")
tar_source("R/03_Plot_length_gasar.R")
tar_source("R/04_AnovaTest_gasar.R")
# Replace the target list below with your own:
list(
tar_target(file, "Data/Allo.csv", format="file"),
tar_target(data, load_gasar(file)), # rds is the default format. see https://docs.ropensci.org/targets/reference/tar_target.html#storage-formats for other formats
tar_target(Resume, Res_gasar(data)),
tar_target(Plot, Plot_length(Resume)),
tar_target(Anova_gasar_Length_Station, AnovaTest_gasar(data, data$Longueurs, data$Station)))
# Sys.setenv(TAR_PROJECT = "Own")
# tar_manifest(fields = command) # to check for mistakes
# tar_visnetwork() # to check for the pipeline architecture
# tar_make() # To run the pipeline
# tar_read() # To see the results
# tar_load() # To load the results
Sys.setenv(TAR_PROJECT = "Own")
tar_visnetwork()
renv::status()
tar_visnetwork()
renv::install("datapasta")
renv::status()
quit()
library(readr)
Allo <- read_delim("Data/Allo.csv", delim = "\t",
escape_double = FALSE, locale = locale(decimal_mark = ","),
trim_ws = TRUE)
View(Allo)
?datapasta
?pastadata
?datapasta
tribble_paste()
datapasta::tribble_paste()
renv::install("reprex")
styler:::style_selection()
reprex()
renv::install("reprex")
reprex::reprex()

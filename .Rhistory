Res <- anova(Obj)
} else(return(paste0("No homoscedasticity, p-value = ", (Lev["group","Pr(>F)"]))))
if(Res["b", "Pr(>F)"] < 0.05){
Post <- TukeyHSD(Obj)
data.frame(Post$b) %>%
rownames_to_column(var="b") %>%
filter(p.adj<0.05)
} else (return("null"))
}
T <- AnovaTest(data=data, a=data$Longueurs, b=data$Station)
T
T <- AnovaTest(data=data, a=data$Longueurs, b=data$Station)
T
AnovaTest <- function(data, a, b){
library(tibble)
library(dplyr)
Obj <- aov(a ~ b, data=data)
Shap <-  shapiro.test(Obj$residuals)
if(Shap["p.value"] > 0.05){
Lev <- leveneTest(Obj$residuals, data$Station)
} else(return("No residual normality"))
if(Lev["group","Pr(>F)"] > 0.001){
Res <- anova(Obj)
} else(return(paste0("No homoscedasticity, p-value = ", (Lev["group","Pr(>F)"]))))
if(Res["b", "Pr(>F)"] < 0.05){
Post <- TukeyHSD(Obj)
data.frame(Post$b) %>%
rownames_to_column(var="b") %>%
filter(p.adj<0.05)
return(Res["b", "Pr(>F)"])
} else (return("null"))
}
T <- AnovaTest(data=data, a=data$Longueurs, b=data$Station)
T
AnovaTest <- function(data, a, b){
library(tibble)
library(dplyr)
Obj <- aov(a ~ b, data=data)
Shap <-  shapiro.test(Obj$residuals)
if(Shap["p.value"] > 0.05){
Lev <- leveneTest(Obj$residuals, data$Station)
} else(return("No residual normality"))
if(Lev["group","Pr(>F)"] > 0.001){
Res <- anova(Obj)
} else(return(paste0("No homoscedasticity, p-value = ", (Lev["group","Pr(>F)"]))))
if(Res["b", "Pr(>F)"] < 0.05){
return(Res["b", "Pr(>F)"])
Post <- TukeyHSD(Obj)
data.frame(Post$b) %>%
rownames_to_column(var="b") %>%
filter(p.adj<0.05)
} else (return("null"))
}
T <- AnovaTest(data=data, a=data$Longueurs, b=data$Station)
T
AnovaTest <- function(data, a, b){
library(tibble)
library(dplyr)
Obj <- aov(a ~ b, data=data)
Shap <-  shapiro.test(Obj$residuals)
if(Shap["p.value"] > 0.05){
Lev <- leveneTest(Obj$residuals, data$Station)
} else(return("No residual normality"))
if(Lev["group","Pr(>F)"] > 0.001){
Res <- anova(Obj)
} else(return(paste0("No homoscedasticity, p-value = ", (Lev["group","Pr(>F)"]))))
if(Res["b", "Pr(>F)"] < 0.05){
Post <- TukeyHSD(Obj)
return(Res["b", "Pr(>F)"])
return(data.frame(Post$b) %>%
rownames_to_column(var="b") %>%
filter(p.adj<0.05))
} else (return("null"))
}
T <- AnovaTest(data=data, a=data$Longueurs, b=data$Station)
T
AnovaTest <- function(data, a, b){
library(tibble)
library(dplyr)
Obj <- aov(a ~ b, data=data)
Shap <-  shapiro.test(Obj$residuals)
if(Shap["p.value"] > 0.05){
Lev <- leveneTest(Obj$residuals, data$Station)
} else(return("No residual normality"))
if(Lev["group","Pr(>F)"] > 0.001){
Res <- anova(Obj)
} else(return(paste0("No homoscedasticity, p-value = ", (Lev["group","Pr(>F)"]))))
if(Res["b", "Pr(>F)"] < 0.05){
Post <- TukeyHSD(Obj)
data.frame(Post$b) %>%
rownames_to_column(var="b") %>%
filter(p.adj<0.05))
T <- AnovaTest(data=data, a=data$Longueurs, b=data$Station)
T
AnovaTest <- function(data, a, b){
library(tibble)
library(dplyr)
Obj <- aov(a ~ b, data=data)
Shap <-  shapiro.test(Obj$residuals)
if(Shap["p.value"] > 0.05){
Lev <- leveneTest(Obj$residuals, data$Station)
} else(return("No residual normality"))
if(Lev["group","Pr(>F)"] > 0.001){
Res <- anova(Obj)
} else(return(paste0("No homoscedasticity, p-value = ", (Lev["group","Pr(>F)"]))))
if(Res["b", "Pr(>F)"] < 0.05){
Post <- TukeyHSD(Obj)
data.frame(Post$b) %>%
rownames_to_column(var="b") %>%
filter(p.adj<0.05))
AnovaTest <- function(data, a, b){
library(tibble)
library(dplyr)
Obj <- aov(a ~ b, data=data)
Shap <-  shapiro.test(Obj$residuals)
if(Shap["p.value"] > 0.05){
Lev <- leveneTest(Obj$residuals, data$Station)
} else(return("No residual normality"))
if(Lev["group","Pr(>F)"] > 0.001){
Res <- anova(Obj)
} else(return(paste0("No homoscedasticity, p-value = ", (Lev["group","Pr(>F)"]))))
if(Res["b", "Pr(>F)"] < 0.05){
Post <- TukeyHSD(Obj)
data.frame(Post$b) %>%
rownames_to_column(var="b") %>%
filter(p.adj<0.05)
} else (return("null"))
}
T <- AnovaTest(data=data, a=data$Longueurs, b=data$Station)
T
AnovaTest <- function(data, a, b){
library(tibble)
library(dplyr)
Obj <- aov(a ~ b, data=data)
Shap <-  shapiro.test(Obj$residuals)
if(Shap["p.value"] > 0.05){
Lev <- leveneTest(Obj$residuals, data$Station)
} else(return("No residual normality"))
if(Lev["group","Pr(>F)"] > 0.001){
Res <- anova(Obj)
} else(return(paste0("No homoscedasticity, p-value = ", (Lev["group","Pr(>F)"]))))
if(Res["b", "Pr(>F)"] < 0.05){
Post <- TukeyHSD(Obj)
data.frame(Post$b) %>%
rownames_to_column(var="b") %>%
filter(p.adj<0.05)
return(Res["b", "Pr(>F)"])
} else (return("null"))
}
T <- AnovaTest(data=data, a=data$Longueurs, b=data$Station)
T
AnovaTest <- function(data, a, b){
library(tibble)
library(dplyr)
Obj <- aov(a ~ b, data=data)
Shap <-  shapiro.test(Obj$residuals)
if(Shap["p.value"] > 0.05){
Lev <- leveneTest(Obj$residuals, data$Station)
} else(return("No residual normality"))
if(Lev["group","Pr(>F)"] > 0.001){
Res <- anova(Obj)
} else(return(paste0("No homoscedasticity, p-value = ", (Lev["group","Pr(>F)"]))))
if(Res["b", "Pr(>F)"] < 0.05){
Post <- TukeyHSD(Obj)
data.frame(Post$b) %>%
rownames_to_column(var="b") %>%
filter(p.adj<0.05)
} else (return("null"))
}
T <- AnovaTest(data=data, a=data$Longueurs, b=data$Station)
T
AnovaTest <- function(data, a, b){
library(tibble)
library(dplyr)
Obj <- aov(a ~ b, data=data)
Shap <-  shapiro.test(Obj$residuals)
if(Shap["p.value"] > 0.05){
Lev <- leveneTest(Obj$residuals, data$Station)
} else(return("No residual normality"))
if(Lev["group","Pr(>F)"] > 0.001){
Res <- anova(Obj)
} else(return(paste0("No homoscedasticity, p-value = ", (Lev["group","Pr(>F)"]))))
if(Res["b", "Pr(>F)"] < 0.05){
Post <- TukeyHSD(Obj)
return(data.frame(Post$b) %>%
rownames_to_column(var="b") %>%
filter(p.adj<0.05))
return(Res["b", "Pr(>F)"])
} else (return("null"))
}
T <- AnovaTest(data=data, a=data$Longueurs, b=data$Station)
T
?return()
AnovaTest <- function(data, a, b){
AnovaTest <- function(data, a, b){
library(dplyr)
Obj <- aov(a ~ b, data=data)
)
AnovaTest <- function(data, a, b){
library(tibble)
library(dplyr)
Obj <- aov(a ~ b, data=data)
Shap <-  shapiro.test(Obj$residuals)
if(Shap["p.value"] > 0.05){
Lev <- leveneTest(Obj$residuals, data$Station)
} else(return("No residual normality"))
if(Lev["group","Pr(>F)"] > 0.001){
Res <- anova(Obj)
} else(return(paste0("No homoscedasticity, p-value = ", (Lev["group","Pr(>F)"]))))
if(Res["b", "Pr(>F)"] < 0.05){
Post <- TukeyHSD(Obj)
return(list(data.frame(Post$b) %>%
rownames_to_column(var="b") %>%
filter(p.adj<0.05),Res["b", "Pr(>F)"]))
} else (return("null"))
}
T <- AnovaTest(data=data, a=data$Longueurs, b=data$Station)
T
# Load packages required to define the pipeline:
library(targets)
# Set target options:
tar_option_set(
packages = c("readr", "dplyr", "ggplot2", "tibble") # Packages that your targets need for their tasks.
# format = "qs", # Optionally set the default storage format. qs is fast.
#
# Pipelines that take a long time to run may benefit from
# optional distributed computing. To use this capability
# in tar_make(), supply a {crew} controller
# as discussed at https://books.ropensci.org/targets/crew.html.
# Choose a controller that suits your needs. For example, the following
# sets a controller that scales up to a maximum of two workers
# which run as local R processes. Each worker launches when there is work
# to do and exits if 60 seconds pass with no tasks to run.
#
#   controller = crew::crew_controller_local(workers = 2, seconds_idle = 60)
#
# Alternatively, if you want workers to run on a high-performance computing
# cluster, select a controller from the {crew.cluster} package.
# For the cloud, see plugin packages like {crew.aws.batch}.
# The following example is a controller for Sun Grid Engine (SGE).
#
#   controller = crew.cluster::crew_controller_sge(
#     # Number of workers that the pipeline can scale up to:
#     workers = 10,
#     # It is recommended to set an idle time so workers can shut themselves
#     # down if they are not running tasks.
#     seconds_idle = 120,
#     # Many clusters install R as an environment module, and you can load it
#     # with the script_lines argument. To select a specific verison of R,
#     # you may need to include a version string, e.g. "module load R/4.3.2".
#     # Check with your system administrator if you are unsure.
#     script_lines = "module load R"
#   )
#
# Set other options as needed.
)
# Run the R scripts in the R/ folder with your custom functions:
tar_source("R/FUNCTIONS.R")
# Replace the target list below with your own:
list(
tar_target(file, "Data/Allo.csv", format="file"),
tar_target(data, load_gasar(file)),
tar_target(Resume, Res_gasar(data)),
tar_target(Plot, Plot_length(Resume)),
tar_target(Anova_gasar_Length_Station, AnovaTest(data, data$Longueurs, data$Station)))
Sys.setenv(TAR_PROJECT = "Own")
tar_manifest(fields = command)
tar_make()
# Load packages required to define the pipeline:
library(targets)
# Set target options:
tar_option_set(
packages = c("readr", "dplyr", "ggplot2", "tibble", "car") # Packages that your targets need for their tasks.
# format = "qs", # Optionally set the default storage format. qs is fast.
#
# Pipelines that take a long time to run may benefit from
# optional distributed computing. To use this capability
# in tar_make(), supply a {crew} controller
# as discussed at https://books.ropensci.org/targets/crew.html.
# Choose a controller that suits your needs. For example, the following
# sets a controller that scales up to a maximum of two workers
# which run as local R processes. Each worker launches when there is work
# to do and exits if 60 seconds pass with no tasks to run.
#
#   controller = crew::crew_controller_local(workers = 2, seconds_idle = 60)
#
# Alternatively, if you want workers to run on a high-performance computing
# cluster, select a controller from the {crew.cluster} package.
# For the cloud, see plugin packages like {crew.aws.batch}.
# The following example is a controller for Sun Grid Engine (SGE).
#
#   controller = crew.cluster::crew_controller_sge(
#     # Number of workers that the pipeline can scale up to:
#     workers = 10,
#     # It is recommended to set an idle time so workers can shut themselves
#     # down if they are not running tasks.
#     seconds_idle = 120,
#     # Many clusters install R as an environment module, and you can load it
#     # with the script_lines argument. To select a specific verison of R,
#     # you may need to include a version string, e.g. "module load R/4.3.2".
#     # Check with your system administrator if you are unsure.
#     script_lines = "module load R"
#   )
#
# Set other options as needed.
)
# Run the R scripts in the R/ folder with your custom functions:
tar_source("R/FUNCTIONS.R")
# Replace the target list below with your own:
list(
tar_target(file, "Data/Allo.csv", format="file"),
tar_target(data, load_gasar(file)),
tar_target(Resume, Res_gasar(data)),
tar_target(Plot, Plot_length(Resume)),
tar_target(Anova_gasar_Length_Station, AnovaTest(data, data$Longueurs, data$Station)))
Sys.setenv(TAR_PROJECT = "Own")
tar_make()
?leveneTest()
# Set target options:
tar_option_set(
packages = c("readr", "dplyr", "ggplot2", "tibble", "car") # Packages that your targets need for their tasks.
# format = "qs", # Optionally set the default storage format. qs is fast.
#
# Pipelines that take a long time to run may benefit from
# optional distributed computing. To use this capability
# in tar_make(), supply a {crew} controller
# as discussed at https://books.ropensci.org/targets/crew.html.
# Choose a controller that suits your needs. For example, the following
# sets a controller that scales up to a maximum of two workers
# which run as local R processes. Each worker launches when there is work
# to do and exits if 60 seconds pass with no tasks to run.
#
#   controller = crew::crew_controller_local(workers = 2, seconds_idle = 60)
#
# Alternatively, if you want workers to run on a high-performance computing
# cluster, select a controller from the {crew.cluster} package.
# For the cloud, see plugin packages like {crew.aws.batch}.
# The following example is a controller for Sun Grid Engine (SGE).
#
#   controller = crew.cluster::crew_controller_sge(
#     # Number of workers that the pipeline can scale up to:
#     workers = 10,
#     # It is recommended to set an idle time so workers can shut themselves
#     # down if they are not running tasks.
#     seconds_idle = 120,
#     # Many clusters install R as an environment module, and you can load it
#     # with the script_lines argument. To select a specific verison of R,
#     # you may need to include a version string, e.g. "module load R/4.3.2".
#     # Check with your system administrator if you are unsure.
#     script_lines = "module load R"
#   )
#
# Set other options as needed.
)
# Run the R scripts in the R/ folder with your custom functions:
tar_source("R/FUNCTIONS.R")
# Replace the target list below with your own:
list(
tar_target(file, "Data/Allo.csv", format="file"),
tar_target(data, load_gasar(file)),
tar_target(Resume, Res_gasar(data)),
tar_target(Plot, Plot_length(Resume)),
tar_target(Anova_gasar_Length_Station, AnovaTest(data, data$Longueurs, data$Station)))
Sys.setenv(TAR_PROJECT = "Own")
tar_make()
# Replace the target list below with your own:
list(
tar_target(file, "Data/Allo.csv", format="file"),
tar_target(data, load_gasar(file)),
tar_target(Resume, Res_gasar(data)),
tar_target(Plot, Plot_length(Resume)),
tar_target(Anova_gasar_Length_Station, AnovaTest(data, data$Longueurs, data$Station)))
tar_make()
targets::tar_meta(fields = warnings, complete_only = TRUE)
tar_read(Anova_gasar_Length_Station)
tar_visnetwork()
# Replace the target list below with your own:
list(
tar_target(file, "Data/Allo.csv", format="file"),
tar_target(data, load_gasar(file), format = "rsd"),
tar_target(Resume, Res_gasar(data), format = "rsd"),
tar_target(Plot, Plot_length(Resume), format = "rsd"),
tar_target(Anova_gasar_Length_Station, AnovaTest(data, data$Longueurs, data$Station), format = "rsd"))
?tar_target()
?tar_option_get
tar_load(plot)
tar_load(Plot)
Plot
class(Plot)
tar_visnetwork()
# Replace the target list below with your own:
list(
tar_target(file, "Data/Allo.csv", format="file"),
tar_target(data, load_gasar(file), format = "rds"), # rds is the default format. see https://docs.ropensci.org/targets/reference/tar_target.html#storage-formats for other formats
tar_target(Resume, Res_gasar(data), format = "rds"),
tar_target(Plot, Plot_length(Resume), format = "rds"),
tar_target(Anova_gasar_Length_Station, AnovaTest(data, data$Longueurs, data$Station), format = "rsd"))
# Replace the target list below with your own:
list(
tar_target(file, "Data/Allo.csv", format="file"),
tar_target(data, load_gasar(file), format = "rds"), # rds is the default format. see https://docs.ropensci.org/targets/reference/tar_target.html#storage-formats for other formats
tar_target(Resume, Res_gasar(data), format = "rds"),
tar_target(Plot, Plot_length(Resume), format = "rds"),
tar_target(Anova_gasar_Length_Station, AnovaTest(data, data$Longueurs, data$Station), format = "rds"))
tar_visnetwork()
# Load packages required to define the pipeline:
library(targets)
# Set target options:
tar_option_set(
packages = c("readr", "dplyr", "ggplot2", "tibble", "car") # Packages that your targets need for their tasks.
# format = "qs", # Optionally set the default storage format. qs is fast.
#
# Pipelines that take a long time to run may benefit from
# optional distributed computing. To use this capability
# in tar_make(), supply a {crew} controller
# as discussed at https://books.ropensci.org/targets/crew.html.
# Choose a controller that suits your needs. For example, the following
# sets a controller that scales up to a maximum of two workers
# which run as local R processes. Each worker launches when there is work
# to do and exits if 60 seconds pass with no tasks to run.
#
#   controller = crew::crew_controller_local(workers = 2, seconds_idle = 60)
#
# Alternatively, if you want workers to run on a high-performance computing
# cluster, select a controller from the {crew.cluster} package.
# For the cloud, see plugin packages like {crew.aws.batch}.
# The following example is a controller for Sun Grid Engine (SGE).
#
#   controller = crew.cluster::crew_controller_sge(
#     # Number of workers that the pipeline can scale up to:
#     workers = 10,
#     # It is recommended to set an idle time so workers can shut themselves
#     # down if they are not running tasks.
#     seconds_idle = 120,
#     # Many clusters install R as an environment module, and you can load it
#     # with the script_lines argument. To select a specific verison of R,
#     # you may need to include a version string, e.g. "module load R/4.3.2".
#     # Check with your system administrator if you are unsure.
#     script_lines = "module load R"
#   )
#
# Set other options as needed.
)
# Run the R scripts in the R/ folder with your custom functions:
tar_source("R/Own/FUNCTIONS.R")
# Replace the target list below with your own:
list(
tar_target(file, "Data/Allo.csv", format="file"),
tar_target(data, load_gasar(file), format = "rds"), # rds is the default format. see https://docs.ropensci.org/targets/reference/tar_target.html#storage-formats for other formats
tar_target(Resume, Res_gasar(data), format = "rds"),
tar_target(Plot, Plot_length(Resume), format = "rds"),
tar_target(Anova_gasar_Length_Station, AnovaTest(data, data$Longueurs, data$Station), format = "rds"))
Sys.setenv(TAR_PROJECT = "Own")
tar_manifest(fields = command)
View(load_gasar)
# Load packages required to define the pipeline:
library(targets)
# Set target options:
tar_option_set(
packages = c("readr", "dplyr", "ggplot2", "tibble", "car") # Packages that your targets need for their tasks.
# format = "qs", # Optionally set the default storage format. qs is fast.
#
# Pipelines that take a long time to run may benefit from
# optional distributed computing. To use this capability
# in tar_make(), supply a {crew} controller
# as discussed at https://books.ropensci.org/targets/crew.html.
# Choose a controller that suits your needs. For example, the following
# sets a controller that scales up to a maximum of two workers
# which run as local R processes. Each worker launches when there is work
# to do and exits if 60 seconds pass with no tasks to run.
#
#   controller = crew::crew_controller_local(workers = 2, seconds_idle = 60)
#
# Alternatively, if you want workers to run on a high-performance computing
# cluster, select a controller from the {crew.cluster} package.
# For the cloud, see plugin packages like {crew.aws.batch}.
# The following example is a controller for Sun Grid Engine (SGE).
#
#   controller = crew.cluster::crew_controller_sge(
#     # Number of workers that the pipeline can scale up to:
#     workers = 10,
#     # It is recommended to set an idle time so workers can shut themselves
#     # down if they are not running tasks.
#     seconds_idle = 120,
#     # Many clusters install R as an environment module, and you can load it
#     # with the script_lines argument. To select a specific verison of R,
#     # you may need to include a version string, e.g. "module load R/4.3.2".
#     # Check with your system administrator if you are unsure.
#     script_lines = "module load R"
#   )
#
# Set other options as needed.
)
# Run the R scripts in the R/ folder with your custom functions:
tar_source("R/Own/FUNCTIONS.R")
# Replace the target list below with your own:
list(
tar_target(file, "Data/Allo.csv", format="file"),
tar_target(data, load_gasar(file), format = "rds"), # rds is the default format. see https://docs.ropensci.org/targets/reference/tar_target.html#storage-formats for other formats
tar_target(Resume, Res_gasar(data), format = "rds"),
tar_target(Plot, Plot_length(Resume), format = "rds"),
tar_target(Anova_gasar_Length_Station, AnovaTest(data, data$Longueurs, data$Station), format = "rds"))
# Replace the target list below with your own:
list(
tar_target(file, "Data/Allo.csv", format="file"),
tar_target(data, load_gasar(file)), # rds is the default format. see https://docs.ropensci.org/targets/reference/tar_target.html#storage-formats for other formats
tar_target(Resume, Res_gasar(data)),
tar_target(Plot, Plot_length(Resume)),
tar_target(Anova_gasar_Length_Station, AnovaTest(data, data$Longueurs, data$Station)))
Sys.setenv(TAR_PROJECT = "Own")
tar_manifest(fields = command)
tar_visnetwork()
